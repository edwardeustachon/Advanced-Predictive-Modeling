{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">MIS 382N: ADVANCED PREDICTIVE MODELING - MSBA</p>\n",
    "# <p style=\"text-align: center;\">Assignment 1</p>\n",
    "## <p style=\"text-align: center;\">Total points: 100</p>\n",
    "## <p style=\"text-align: center;\">Due: Tuesday, September 17 submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Your partner needs to be from the same section. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTEID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TA know. \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Challenges in Data Science (10 pts)\n",
    "\n",
    "Refer to the Domino guide under Modules --> Additional Resources\n",
    "\n",
    "Section 2 describes 8 Challenges. You may have personally encountered or heard of somebody else who encountered some of these challenge. If so,  please write 1-2 paragraphs on what situation was encountered and how it mapped into one the mentioned challenges. If not, think of a hypothetical case and do the same exercise. \n",
    "\n",
    "\n",
    "## Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: MLE Estimate (5+10+10 points)\n",
    "\n",
    "Consider a coin tossing experiment where a biased coin is tossed repeatedly for $n$ times with independence in successive tosses. \n",
    "If we record the outcome of each toss as $X_{i}$, for $i \\in \\{1,2,3,....,n\\}$ as follows\n",
    "\n",
    "$  \n",
    "X_{i} = \n",
    "     \\begin{cases}\n",
    "       \\text{1,} &\\quad\\text{if $i^{th}$ toss results in $Heads$,}\\\\\n",
    "       \\text{0,} &\\quad\\text{otherwise.} \\\\ \n",
    "     \\end{cases}\n",
    "$\n",
    "\n",
    "then $X_{1}, X_{2}, .... X_{n}$ will be a sequence of $0$'s and $1$'s. Assume that for this coin $P(Heads) = p$, which of course is not known to the experimenter. \n",
    "\n",
    "1. The log-likelihood function of the observations, as discussed in the class, denotes the probability of occurrence of the observations. Write the log-likelihood function for the set of observations $X_{1}, X_{2}, .... X_{n}$. \n",
    "\n",
    "2. Compute an MLE estimate of $p$.\n",
    "\n",
    "3. Check if the obtained estimate is unbiased.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Multiple Linear Regression in Python (30 pts)\n",
    "\n",
    "Use the following code to import the California housing prices dataset and linear models in python. The dataset is taken from https://www.kaggle.com/camnugent/california-housing-prices/version/1. I have removed the categorical variables and rows with missing variables to make it easier to run the models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"reduced_data.csv\")\n",
    "X = train_df.drop(['median_house_value'],axis=1)\n",
    "Y = train_df['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. (2 pts) Print the shape (number of rows and columns) of the feature matrix X, and print the first 5 rows.\n",
    "\n",
    "b.  (6 pts) Using ordinary least squares, fit a multiple linear regression (MLR) on all the feature variables using the entire dataset. Report the regression coefficient of each input feature and evaluate the model using mean absolute error (MAE).  Example of ordinary least squares in Python is shown in Section 1.1.1 of http://scikit-learn.org/stable/modules/linear_model.html.\n",
    "\n",
    "c.  (6 pts) Split the data into a training set and a test set, using the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) with test_size = 0.30 and random_state = 11. Fit an MLR using the training set.  Evaluate the trained model using the training set and the test set, respectively.  Compare the two MAE values thus obtained.\n",
    "\n",
    "d.  (5 pts) Calculate the pearson correlation matrix of the independent variables in the training set (you can use [this](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)). Report the variables which have magnitude of correlation greater than 0.9 w.r.t the variable 'households'. \n",
    "\n",
    "e.  (6 pts) Add the following independent variables to both train and test sets:\n",
    "1. average_bedrooms = total_bedrooms/households\n",
    "2. average_rooms = total_rooms/households\n",
    "3. average_population = total_rooms/households\n",
    "\n",
    "Recalculate the correlation matrix. What do you observe about the correlation values of the above new variables?\n",
    "\n",
    "f. (5 pts) Fit an MLR on the new train data (with additional independent variables) and report the MAE on the new train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20433, 8)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-4.27301205e+04 -4.25097369e+04  1.15790031e+03 -8.24972507e+00\n",
      "  1.13820707e+02 -3.83855780e+01  4.77013513e+01  4.02975217e+04]\n",
      "MAE: 50799.63\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(X, Y)\n",
    "\n",
    "print(\"Coefficients: {}\".format(reg.coef_))\n",
    "print(\"MAE: %.2f\"\n",
    "      % mean_absolute_error(Y, reg.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set MAE: 50749.10\n",
      "Test Set MAE: 50916.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 11)\n",
    "reg.fit(X_train, Y_train)\n",
    "Y_train_pred = reg.predict(X_train)\n",
    "Y_test_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"Training Set MAE: %.2f\"\n",
    "      % mean_absolute_error(Y_train, Y_train_pred))\n",
    "print(\"Test Set MAE: %.2f\"\n",
    "      % mean_absolute_error(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rooms       0.916556\n",
       "total_bedrooms    0.979547\n",
       "population        0.910283\n",
       "households        1.000000\n",
       "Name: households, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = pd.DataFrame.corr(X_train, method = \"pearson\")\n",
    "corr_matrix[\"households\"][abs(corr_matrix[\"households\"] > .9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent variables having correlation greater than 0.9 w.r.t 'households': \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>average_bedrooms</th>\n",
       "      <th>average_rooms</th>\n",
       "      <th>average_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.925627</td>\n",
       "      <td>-0.111272</td>\n",
       "      <td>0.042788</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.101596</td>\n",
       "      <td>0.056116</td>\n",
       "      <td>-0.020466</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.027099</td>\n",
       "      <td>0.011811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.925627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>-0.034147</td>\n",
       "      <td>-0.066424</td>\n",
       "      <td>-0.109600</td>\n",
       "      <td>-0.070537</td>\n",
       "      <td>-0.074943</td>\n",
       "      <td>0.062059</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>-0.002330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>-0.111272</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.356534</td>\n",
       "      <td>-0.316644</td>\n",
       "      <td>-0.294652</td>\n",
       "      <td>-0.298702</td>\n",
       "      <td>-0.115736</td>\n",
       "      <td>-0.077163</td>\n",
       "      <td>-0.158539</td>\n",
       "      <td>0.012569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>0.042788</td>\n",
       "      <td>-0.034147</td>\n",
       "      <td>-0.356534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927454</td>\n",
       "      <td>0.859323</td>\n",
       "      <td>0.916556</td>\n",
       "      <td>0.198486</td>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.146227</td>\n",
       "      <td>-0.031031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>0.069305</td>\n",
       "      <td>-0.066424</td>\n",
       "      <td>-0.316644</td>\n",
       "      <td>0.927454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880929</td>\n",
       "      <td>0.979547</td>\n",
       "      <td>-0.013082</td>\n",
       "      <td>0.054525</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.036556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.101596</td>\n",
       "      <td>-0.109600</td>\n",
       "      <td>-0.294652</td>\n",
       "      <td>0.859323</td>\n",
       "      <td>0.880929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>-0.062026</td>\n",
       "      <td>-0.072951</td>\n",
       "      <td>0.077684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>0.056116</td>\n",
       "      <td>-0.070537</td>\n",
       "      <td>-0.298702</td>\n",
       "      <td>0.916556</td>\n",
       "      <td>0.979547</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>-0.081950</td>\n",
       "      <td>-0.034892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>-0.020466</td>\n",
       "      <td>-0.074943</td>\n",
       "      <td>-0.115736</td>\n",
       "      <td>0.198486</td>\n",
       "      <td>-0.013082</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059447</td>\n",
       "      <td>0.350785</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_bedrooms</th>\n",
       "      <td>0.017548</td>\n",
       "      <td>0.062059</td>\n",
       "      <td>-0.077163</td>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.054525</td>\n",
       "      <td>-0.062026</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>-0.059447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833841</td>\n",
       "      <td>-0.002194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_rooms</th>\n",
       "      <td>-0.027099</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>-0.158539</td>\n",
       "      <td>0.146227</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.072951</td>\n",
       "      <td>-0.081950</td>\n",
       "      <td>0.350785</td>\n",
       "      <td>0.833841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_population</th>\n",
       "      <td>0.011811</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>-0.031031</td>\n",
       "      <td>-0.036556</td>\n",
       "      <td>0.077684</td>\n",
       "      <td>-0.034892</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    longitude  latitude  housing_median_age  total_rooms  \\\n",
       "longitude            1.000000 -0.925627           -0.111272     0.042788   \n",
       "latitude            -0.925627  1.000000            0.013098    -0.034147   \n",
       "housing_median_age  -0.111272  0.013098            1.000000    -0.356534   \n",
       "total_rooms          0.042788 -0.034147           -0.356534     1.000000   \n",
       "total_bedrooms       0.069305 -0.066424           -0.316644     0.927454   \n",
       "population           0.101596 -0.109600           -0.294652     0.859323   \n",
       "households           0.056116 -0.070537           -0.298702     0.916556   \n",
       "median_income       -0.020466 -0.074943           -0.115736     0.198486   \n",
       "average_bedrooms     0.017548  0.062059           -0.077163     0.036170   \n",
       "average_rooms       -0.027099  0.104294           -0.158539     0.146227   \n",
       "average_population   0.011811 -0.002330            0.012569    -0.031031   \n",
       "\n",
       "                    total_bedrooms  population  households  median_income  \\\n",
       "longitude                 0.069305    0.101596    0.056116      -0.020466   \n",
       "latitude                 -0.066424   -0.109600   -0.070537      -0.074943   \n",
       "housing_median_age       -0.316644   -0.294652   -0.298702      -0.115736   \n",
       "total_rooms               0.927454    0.859323    0.916556       0.198486   \n",
       "total_bedrooms            1.000000    0.880929    0.979547      -0.013082   \n",
       "population                0.880929    1.000000    0.910283      -0.001523   \n",
       "households                0.979547    0.910283    1.000000       0.008033   \n",
       "median_income            -0.013082   -0.001523    0.008033       1.000000   \n",
       "average_bedrooms          0.054525   -0.062026   -0.050050      -0.059447   \n",
       "average_rooms             0.004237   -0.072951   -0.081950       0.350785   \n",
       "average_population       -0.036556    0.077684   -0.034892       0.000417   \n",
       "\n",
       "                    average_bedrooms  average_rooms  average_population  \n",
       "longitude                   0.017548      -0.027099            0.011811  \n",
       "latitude                    0.062059       0.104294           -0.002330  \n",
       "housing_median_age         -0.077163      -0.158539            0.012569  \n",
       "total_rooms                 0.036170       0.146227           -0.031031  \n",
       "total_bedrooms              0.054525       0.004237           -0.036556  \n",
       "population                 -0.062026      -0.072951            0.077684  \n",
       "households                 -0.050050      -0.081950           -0.034892  \n",
       "median_income              -0.059447       0.350785            0.000417  \n",
       "average_bedrooms            1.000000       0.833841           -0.002194  \n",
       "average_rooms               0.833841       1.000000            0.003475  \n",
       "average_population         -0.002194       0.003475            1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"average_bedrooms\"] = X_train[\"total_bedrooms\"] / X_train[\"households\"]\n",
    "X_train[\"average_rooms\"] = X_train[\"total_rooms\"] / X_train[\"households\"]\n",
    "X_train[\"average_population\"] = X_train[\"population\"] / X_train[\"households\"]\n",
    "\n",
    "X_test[\"average_bedrooms\"] = X_test[\"total_bedrooms\"] / X_test[\"households\"]\n",
    "X_test[\"average_rooms\"] = X_test[\"total_rooms\"] / X_test[\"households\"]\n",
    "X_test[\"average_population\"] = X_test[\"population\"] / X_test[\"households\"]\n",
    "\n",
    "corr_matrix = pd.DataFrame.corr(X_train, method = \"pearson\")\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: There is a strong correlation between average_bedrooms and average_rooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set MAE: 50474.27\n",
      "Test Set MAE: 50783.97\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(X_train, Y_train)\n",
    "Y_train_pred = reg.predict(X_train)\n",
    "Y_test_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"Training Set MAE: %.2f\"\n",
    "      % mean_absolute_error(Y_train, Y_train_pred))\n",
    "print(\"Test Set MAE: %.2f\"\n",
    "      % mean_absolute_error(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Ridge and Lasso Regression (30 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same data from before, in this question you will explore the application of Lasso and Ridge regression using sklearn package in Python. Use the same train and test data with additional augmented columns from before. Scale the data so that each of the dependent variables have zero mean and unit variance. You can use the [sklearn.preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "Y_train = scale(Y_train)\n",
    "Y_test = scale(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use sklearn.linear_model.Lasso and sklearn.linear_model.Ridge classes to do a [5-fold cross validation](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py) using sklearn's [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html). For the sweep of the regularization parameter, we will look at a grid of values ranging from $\\lambda = 10^{10}$ to $\\lambda = 10^{-2}$. In Python, you can consider this range of values as follows:\n",
    "\n",
    "      import numpy as np\n",
    "\n",
    "      alphas =  10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "  Report the best chosen $\\lambda$ based on cross validation. The cross validation should happen on your training data using  average MAE as the scoring metric. (8pts)\n",
    "\n",
    "2) Run ridge and lasso for all of the alphas specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; the plots for different features for a method should be on the same plot. What do you qualitatively observe when value of the regularization parameter is changed? (7pts)\n",
    "\n",
    "3) Run least squares regression, ridge, and lasso on the training data. For ridge and lasso, use only the best regularization parameter. Report the prediction error (MAE) on the test data for each. (5pts)\n",
    "\n",
    "4) Run lasso again with cross validation using [sklearn.linear_model.LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). Set the cross validation parameters as follows:\n",
    "\n",
    "    LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "Report the best $\\lambda$ based on cross validation. Run lasso on the training data using the best $\\lambda$ and report the coefficeints for all variables. (5pts)\n",
    "\n",
    "5) Why did we have to scale the data before regularization? (5pts)\n",
    "\n",
    "\n",
    "## Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neg_mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-81b02142d322>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneg_mean_absolute_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_absolute_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'neg_mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso = Lasso(random_state=0, max_iter=10000)\n",
    "alphas =  10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "n_folds = 5\n",
    "\n",
    "clf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, scoring = neg_mean_absolute_error, refit=False)\n",
    "clf.fit(X_train, Y_train)\n",
    "scores = clf.cv_results_['mean_absolute_error']\n",
    "scores_std = clf.cv_results_['std_test_score']\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting ridge coefficents as a function of the regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting lasso coefficents as a function of the regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the alpha parameter obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit lasso using the above alpha and report MAE on Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (5pts)\n",
    "\n",
    "How do you think the performance of your model varies in the train and test set as you increase(decrease) the number of examples in the training dataset? Explain why does it change in a particular way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "For the train set, increasing the number of examples in the training dataset will improve the performance of the model. While the amount of improvement will eventually taper off, given that a model can only be so accurate, more examples is always an improvement.\n",
    "\n",
    "For the test set, increasing the number of examples in the training dataset will initially improve the performance of the model, but eventually the performance will begin to decrease. This is because adding more examples can cause the model to overfit the data, no longer allowing it to effectively predict future behavior. Alternatively, too few datapoints can assign too much weight to each example, also decreasing performance. There is an undefined number of examples where the impact of weight and fitting are minimized and performance peaks. This is the amount we're trying to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
